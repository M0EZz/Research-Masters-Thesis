{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94164d61-6a9b-45a7-b1f6-40231f74b24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (4.11.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: selenium in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (4.20.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from selenium) (2023.5.7)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: webdriver_manager in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (4.0.1)\n",
      "Requirement already satisfied: packaging in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from webdriver_manager) (22.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from webdriver_manager) (1.0.1)\n",
      "Requirement already satisfied: requests in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from webdriver_manager) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from requests->webdriver_manager) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from requests->webdriver_manager) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from requests->webdriver_manager) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: openpyxl in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (3.0.10)\n",
      "Requirement already satisfied: et_xmlfile in /Users/helgegeurtjacobusmoes/anaconda3/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install requests beautifulsoup4\n",
    "! pip install selenium\n",
    "! pip install webdriver_manager\n",
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070e0a67-2a18-4ef1-9b6a-1d0b6f23b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a7fe130-bf01-4ebe-bac2-3849679d8ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/helgegeurtjacobusmoes/Desktop/Thesis Data\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01443f5d-962d-41d2-a284-52c399fc5a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Headline   \n",
      "0  Dit apparaat geeft je extra power tijdens het ...  \\\n",
      "1  Kunstmatige intelligentie verslaat artsen bij ...   \n",
      "2                   Microsoft lijft OpenAI-topman in   \n",
      "3  Waar komt het idee vandaan dat computers tot l...   \n",
      "4                             Robot lacht om grapjes   \n",
      "\n",
      "                                         Publication   \n",
      "0              Trouw, Wetenschap; Blz. 17, 795 words  \\\n",
      "1                Trouw, Nederland; Blz. 8, 248 words   \n",
      "2                   Trouw, Vandaag; Blz. 2, 94 words   \n",
      "3  Trouw, Religie en Filosofie; Blz. 10, 11, 1379...   \n",
      "4              Trouw, Buitenland; Blz. 12, 146 words   \n",
      "\n",
      "                                                 URL News Outlet   \n",
      "0  https://advance.lexis.com/api/document?collect...       Trouw  \\\n",
      "1  https://advance.lexis.com/api/document?collect...       Trouw   \n",
      "2  https://advance.lexis.com/api/document?collect...       Trouw   \n",
      "3  https://advance.lexis.com/api/document?collect...       Trouw   \n",
      "4  https://advance.lexis.com/api/document?collect...       Trouw   \n",
      "\n",
      "           Type of News Word Count  \n",
      "0            Wetenschap        795  \n",
      "1             Nederland        248  \n",
      "2               Vandaag         94  \n",
      "3  Religie en Filosofie       1379  \n",
      "4            Buitenland        146  \n"
     ]
    }
   ],
   "source": [
    "def load_data_with_urls(file_path):\n",
    "    # Load the workbook\n",
    "    wb = openpyxl.load_workbook(file_path, data_only=True)\n",
    "    sheet = wb.active\n",
    "\n",
    "    # List to store data along with URLs\n",
    "    data = []\n",
    "    for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row, min_col=1, max_col=2):  # Assuming headlines and publication info are in first two columns\n",
    "        headline_cell, publication_cell = row\n",
    "        headline = headline_cell.value\n",
    "        publication = publication_cell.value\n",
    "        url = headline_cell.hyperlink.target if headline_cell.hyperlink else None\n",
    "        data.append({\n",
    "            'Headline': headline,\n",
    "            'Publication': publication,\n",
    "            'URL': url\n",
    "        })\n",
    "\n",
    "    # Convert list to DataFrame\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load the files into DataFrames with URLs\n",
    "Trouw_df = load_data_with_urls(\"Trouw.xlsx\")\n",
    "Telegraaf_df = load_data_with_urls(\"De Telegraaf.xlsx\")\n",
    "AD_df = load_data_with_urls(\"Algemeen Dagblad.xlsx\")\n",
    "Volkskrant1_df = load_data_with_urls(\"De Volkskrant 1.xlsx\")\n",
    "NRC1_df = load_data_with_urls(\"NRC 1.xlsx\")\n",
    "Financieele1_df = load_data_with_urls(\"Financieele 1.xlsx\")\n",
    "\n",
    "# Sample 20 articles from each DataFrame\n",
    "samples = [\n",
    "    df.sample(20, random_state=1) for df in [Trouw_df, Telegraaf_df, AD_df, Volkskrant1_df, NRC1_df, Financieele1_df]\n",
    "]\n",
    "\n",
    "# Concatenate the sampled DataFrames\n",
    "sampled_df = pd.concat(samples, ignore_index=True)\n",
    "\n",
    "# Regex pattern to handle the extraction from 'Publication' column\n",
    "regex_pattern = r'^(.*?), (.*?)(?:; Blz\\. (?:NaN|\\d+))?, (\\d+) words$'\n",
    "sampled_df[['News Outlet', 'Type of News', 'Word Count']] = sampled_df['Publication'].str.extract(regex_pattern)\n",
    "\n",
    "# Clean up 'Type of News'\n",
    "sampled_df['Type of News'] = sampled_df['Type of News'].str.replace(r'Blz\\. \\d+', '', regex=True)\n",
    "sampled_df['Type of News'] = sampled_df['Type of News'].str.replace(r'[,0-9]+', '', regex=True)\n",
    "sampled_df['Type of News'] = sampled_df['Type of News'].str.strip().str.rstrip(';')\n",
    "\n",
    "# Remove duplicates\n",
    "sampled_df = sampled_df.drop_duplicates()\n",
    "\n",
    "# Display DataFrame\n",
    "print(sampled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0435a912-a687-4db9-818a-23cd6cb5c785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Publication</th>\n",
       "      <th>URL</th>\n",
       "      <th>News Outlet</th>\n",
       "      <th>Type of News</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dit apparaat geeft je extra power tijdens het ...</td>\n",
       "      <td>Trouw, Wetenschap; Blz. 17, 795 words</td>\n",
       "      <td>https://advance.lexis.com/api/document?collect...</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>Wetenschap</td>\n",
       "      <td>795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kunstmatige intelligentie verslaat artsen bij ...</td>\n",
       "      <td>Trouw, Nederland; Blz. 8, 248 words</td>\n",
       "      <td>https://advance.lexis.com/api/document?collect...</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>Nederland</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft lijft OpenAI-topman in</td>\n",
       "      <td>Trouw, Vandaag; Blz. 2, 94 words</td>\n",
       "      <td>https://advance.lexis.com/api/document?collect...</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>Vandaag</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waar komt het idee vandaan dat computers tot l...</td>\n",
       "      <td>Trouw, Religie en Filosofie; Blz. 10, 11, 1379...</td>\n",
       "      <td>https://advance.lexis.com/api/document?collect...</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>Religie en Filosofie</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robot lacht om grapjes</td>\n",
       "      <td>Trouw, Buitenland; Blz. 12, 146 words</td>\n",
       "      <td>https://advance.lexis.com/api/document?collect...</td>\n",
       "      <td>Trouw</td>\n",
       "      <td>Buitenland</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Google zet kunstmatige intelligentie in bij ee...</td>\n",
       "      <td>Het Financieele Dagblad, ONDERNEMEN; Blz. 13, ...</td>\n",
       "      <td>https://advance.lexis.com/api/document?collect...</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>ONDERNEMEN</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Microsoft maakt radicale keuze voor AI</td>\n",
       "      <td>Het Financieele Dagblad, PAGINA 10; Blz. 10, 1...</td>\n",
       "      <td>https://advance.lexis.com/api/document?collect...</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>PAGINA</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Hoe kunstmatige intelligentie het onderwijs ve...</td>\n",
       "      <td>Het Financieele Dagblad, PAGINA 20; Blz. 20, 1...</td>\n",
       "      <td>https://advance.lexis.com/api/document?collect...</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>PAGINA</td>\n",
       "      <td>1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Cyberwaakhond waarschuwt voor explosie phishin...</td>\n",
       "      <td>Het Financieele Dagblad, PAGINA 1; Blz. 1, 741...</td>\n",
       "      <td>https://advance.lexis.com/api/document?collect...</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>PAGINA</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>De toekomst voorspellen</td>\n",
       "      <td>Het Financieele Dagblad, PAGINA 5; Blz. 5, 444...</td>\n",
       "      <td>https://advance.lexis.com/api/document?collect...</td>\n",
       "      <td>Het Financieele Dagblad</td>\n",
       "      <td>PAGINA</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Headline   \n",
       "0    Dit apparaat geeft je extra power tijdens het ...  \\\n",
       "1    Kunstmatige intelligentie verslaat artsen bij ...   \n",
       "2                     Microsoft lijft OpenAI-topman in   \n",
       "3    Waar komt het idee vandaan dat computers tot l...   \n",
       "4                               Robot lacht om grapjes   \n",
       "..                                                 ...   \n",
       "115  Google zet kunstmatige intelligentie in bij ee...   \n",
       "116             Microsoft maakt radicale keuze voor AI   \n",
       "117  Hoe kunstmatige intelligentie het onderwijs ve...   \n",
       "118  Cyberwaakhond waarschuwt voor explosie phishin...   \n",
       "119                            De toekomst voorspellen   \n",
       "\n",
       "                                           Publication   \n",
       "0                Trouw, Wetenschap; Blz. 17, 795 words  \\\n",
       "1                  Trouw, Nederland; Blz. 8, 248 words   \n",
       "2                     Trouw, Vandaag; Blz. 2, 94 words   \n",
       "3    Trouw, Religie en Filosofie; Blz. 10, 11, 1379...   \n",
       "4                Trouw, Buitenland; Blz. 12, 146 words   \n",
       "..                                                 ...   \n",
       "115  Het Financieele Dagblad, ONDERNEMEN; Blz. 13, ...   \n",
       "116  Het Financieele Dagblad, PAGINA 10; Blz. 10, 1...   \n",
       "117  Het Financieele Dagblad, PAGINA 20; Blz. 20, 1...   \n",
       "118  Het Financieele Dagblad, PAGINA 1; Blz. 1, 741...   \n",
       "119  Het Financieele Dagblad, PAGINA 5; Blz. 5, 444...   \n",
       "\n",
       "                                                   URL   \n",
       "0    https://advance.lexis.com/api/document?collect...  \\\n",
       "1    https://advance.lexis.com/api/document?collect...   \n",
       "2    https://advance.lexis.com/api/document?collect...   \n",
       "3    https://advance.lexis.com/api/document?collect...   \n",
       "4    https://advance.lexis.com/api/document?collect...   \n",
       "..                                                 ...   \n",
       "115  https://advance.lexis.com/api/document?collect...   \n",
       "116  https://advance.lexis.com/api/document?collect...   \n",
       "117  https://advance.lexis.com/api/document?collect...   \n",
       "118  https://advance.lexis.com/api/document?collect...   \n",
       "119  https://advance.lexis.com/api/document?collect...   \n",
       "\n",
       "                 News Outlet          Type of News Word Count  \n",
       "0                      Trouw            Wetenschap        795  \n",
       "1                      Trouw             Nederland        248  \n",
       "2                      Trouw               Vandaag         94  \n",
       "3                      Trouw  Religie en Filosofie       1379  \n",
       "4                      Trouw            Buitenland        146  \n",
       "..                       ...                   ...        ...  \n",
       "115  Het Financieele Dagblad            ONDERNEMEN        264  \n",
       "116  Het Financieele Dagblad                PAGINA       1237  \n",
       "117  Het Financieele Dagblad                PAGINA       1359  \n",
       "118  Het Financieele Dagblad                PAGINA        741  \n",
       "119  Het Financieele Dagblad                PAGINA        444  \n",
       "\n",
       "[120 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8b9cc01-f28b-4ed1-923f-d33549267115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "# Write the final sample to an Excel file\n",
    "sampled_df.to_excel(\"Randomized_Sampled_Articles.xlsx\", index=False)\n",
    "\n",
    "# Display the shape of the final DataFrame to verify the size\n",
    "print(\"Final DataFrame shape:\", sampled_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4276cd59-fc3e-45a5-81e9-38d29ed3f73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Headline   \n",
      "0  Dit apparaat geeft je extra power tijdens het ...  \\\n",
      "1  Kunstmatige intelligentie verslaat artsen bij ...   \n",
      "2                   Microsoft lijft OpenAI-topman in   \n",
      "3  Waar komt het idee vandaan dat computers tot l...   \n",
      "4                             Robot lacht om grapjes   \n",
      "\n",
      "                                         Publication   \n",
      "0              Trouw, Wetenschap; Blz. 17, 795 words  \\\n",
      "1                Trouw, Nederland; Blz. 8, 248 words   \n",
      "2                   Trouw, Vandaag; Blz. 2, 94 words   \n",
      "3  Trouw, Religie en Filosofie; Blz. 10, 11, 1379...   \n",
      "4              Trouw, Buitenland; Blz. 12, 146 words   \n",
      "\n",
      "                                                 URL News Outlet   \n",
      "0  https://advance.lexis.com/api/document?collect...       Trouw  \\\n",
      "1  https://advance.lexis.com/api/document?collect...       Trouw   \n",
      "2  https://advance.lexis.com/api/document?collect...       Trouw   \n",
      "3  https://advance.lexis.com/api/document?collect...       Trouw   \n",
      "4  https://advance.lexis.com/api/document?collect...       Trouw   \n",
      "\n",
      "           Type of News  Word Count  \n",
      "0            Wetenschap         795  \n",
      "1             Nederland         248  \n",
      "2               Vandaag          94  \n",
      "3  Religie en Filosofie        1379  \n",
      "4            Buitenland         146  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = '/Users/helgegeurtjacobusmoes/Desktop/Thesis Data/Randomized_Sampled_Articles.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Display the first few rows to understand its structure\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea250d4-5897-4e87-81e6-85c1bc40081d",
   "metadata": {},
   "source": [
    "## Retrieving Body and Publication Date\n",
    "\n",
    "Geckodriver is used to retrieve the missing data that is needed to analyse the news articles. In this case, Mozilla Firefox is used, since it has the most favorable results and it retrieves the data the fastest. \n",
    "\n",
    "Retrieving Body and Published Date\n",
    "\n",
    "Make sure that the driver is in the same work directory as the files that are being crawled. \n",
    "\n",
    "Retrieved from:\n",
    "[https://www.selenium.dev/downloads/](https://www.selenium.dev/downloads/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18004246-ee62-4f16-8f6b-241bd0cf728d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geckodriver found at: /Users/helgegeurtjacobusmoes/Desktop/thesis data/geckodriver\n"
     ]
    }
   ],
   "source": [
    "def find_geckodriver(start_path):\n",
    "    # Define the name of the geckodriver file you're looking for\n",
    "    geckodriver_filename = \"geckodriver\"  # Use \"geckodriver.exe\" on Windows\n",
    "\n",
    "    # Walk through the directory\n",
    "    for root, dirs, files in os.walk(start_path):\n",
    "        if geckodriver_filename in files:\n",
    "            return os.path.join(root, geckodriver_filename)\n",
    "    return None  # Return None if not found\n",
    "\n",
    "# Define the start path. For example, on macOS it might be something like below, adjust based on your username:\n",
    "# start_path = '/Users/your_username/Desktop/thesis data'\n",
    "# On Windows it might be something like below:\n",
    "# start_path = 'C:\\\\Users\\\\your_username\\\\Desktop\\\\thesis data'\n",
    "\n",
    "# Use os.path.expanduser to start at the current user's desktop if you want it more dynamic\n",
    "start_path = os.path.expanduser('~/Desktop/thesis data')\n",
    "\n",
    "# Find geckodriver\n",
    "geckodriver_path = find_geckodriver(start_path)\n",
    "\n",
    "if geckodriver_path:\n",
    "    print(\"geckodriver found at:\", geckodriver_path)\n",
    "else:\n",
    "    print(\"geckodriver not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c2b2f79-40d1-48b1-8774-1068c7541911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    https://advance.lexis.com/api/document?collect...\n",
      "1    https://advance.lexis.com/api/document?collect...\n",
      "2    https://advance.lexis.com/api/document?collect...\n",
      "3    https://advance.lexis.com/api/document?collect...\n",
      "4    https://advance.lexis.com/api/document?collect...\n",
      "Name: URL, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load the Excel file into a DataFrame\n",
    "excel_path = '/Users/helgegeurtjacobusmoes/Desktop/thesis data/Randomized_Sampled_Articles.xlsx'\n",
    "data = pd.read_excel(excel_path)\n",
    "\n",
    "# Assuming URLs are in a column named 'URL', adjust if it's named differently\n",
    "print(data['URL'].head())  # Display first few URLs to confirm correct loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e7c0c-1287-4cf9-88f5-d5b61fce6fc8",
   "metadata": {},
   "source": [
    "def setup_driver():\n",
    "    # Specify the path to GeckoDriver\n",
    "    geckodriver_path = '/Users/helgegeurtjacobusmoes/Desktop/thesis data/geckodriver'\n",
    "    service = Service(executable_path=geckodriver_path)\n",
    "    driver = webdriver.Firefox(service=service)\n",
    "    return driver\n",
    "\n",
    "def fetch_article_details(driver, url):\n",
    "    driver.get(url)\n",
    "    body, publication_date = None, None\n",
    "    try:\n",
    "        # Wait for the publication date element to be present\n",
    "        publication_date_element = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"p.SS_DocumentInfo:last-of-type\"))\n",
    "        )\n",
    "        publication_date = publication_date_element.text if publication_date_element else \"Publication date not found\"\n",
    "\n",
    "        # Get all paragraphs after the \"Body\" header within the article section\n",
    "        body_elements = driver.find_elements(By.XPATH, \"//h2[@id='JUMPTO_Body']/following-sibling::p\")\n",
    "        body_text_list = [element.text for element in body_elements if element.text.strip() != '']\n",
    "\n",
    "        # Check if we have the ending phrase to stop at\n",
    "        for paragraph in body_text_list:\n",
    "            if \"Bekijk de oorspronkelijke pagina\" in paragraph:\n",
    "                break\n",
    "            if body:\n",
    "                body += \"\\n\" + paragraph\n",
    "            else:\n",
    "                body = paragraph\n",
    "\n",
    "    except (NoSuchElementException, TimeoutException) as e:\n",
    "        print(f\"Error fetching details for URL {url}: {e}\")\n",
    "\n",
    "    return body, publication_date\n",
    "\n",
    "def main():\n",
    "    driver = setup_driver()\n",
    "\n",
    "    # Load your data here\n",
    "    data = pd.read_excel('/Users/helgegeurtjacobusmoes/Desktop/thesis data/Randomized_Sampled_Articles.xlsx')\n",
    "\n",
    "    # Add new columns for body and publication date\n",
    "    data['Body'] = None\n",
    "    data['Publication Date'] = None\n",
    "\n",
    "    # Process all entries in the dataframe\n",
    "    for index, row in data.iterrows():\n",
    "        if pd.notna(row['URL']):\n",
    "            body, publication_date = fetch_article_details(driver, row['URL'])\n",
    "            data.at[index, 'Body'] = body\n",
    "            data.at[index, 'Publication Date'] = publication_date\n",
    "            print(f\"Processed index {index}: {row['URL']}\")\n",
    "        else:\n",
    "            print(f\"URL missing for index {index}\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Check the dataframe's head to confirm the columns are present\n",
    "    print(data.head())\n",
    "    \n",
    "    # Save the updated dataframe to a new Excel file\n",
    "    updated_file_path = '/Users/helgegeurtjacobusmoes/Desktop/thesis data/Updated_Randomized_Sampled_Articles.xlsx'\n",
    "    data.to_excel(updated_file_path, index=False)\n",
    "\n",
    "    print(f\"Updated data has been saved to: {updated_file_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6c38bc-4f31-4dde-a8cc-a587878591d1",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "\n",
    "The Body and the publications are cleaned in order to make them more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00f38f-c38e-4b99-a77c-e856a37a29cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file into a DataFrame\n",
    "excel_path = '/Users/helgegeurtjacobusmoes/Desktop/thesis data/Updated_Randomized_Sampled_Articles.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc3201-cb5e-4ad1-bb60-82323fc661a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Excel file into a DataFrame\n",
    "excel_path = '/Users/helgegeurtjacobusmoes/Desktop/thesis data/Updated_Randomized_Sampled_Articles.xlsx'\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "updated_randomized_sampled_articles = pd.read_excel(excel_path)\n",
    "\n",
    "updated_randomized_sampled_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcd28c-609b-435a-ade5-0e1c7aff89e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary for Dutch to English month translation\n",
    "dutch_months = {\n",
    "    \"januari\": \"January\", \"februari\": \"February\", \"maart\": \"March\",\n",
    "    \"april\": \"April\", \"mei\": \"May\", \"juni\": \"June\",\n",
    "    \"juli\": \"July\", \"augustus\": \"August\", \"september\": \"September\",\n",
    "    \"oktober\": \"October\", \"november\": \"November\", \"december\": \"December\"\n",
    "}\n",
    "\n",
    "# Function to translate Dutch month names to English and format the date\n",
    "def translate_date(date_str):\n",
    "    parts = date_str.split()\n",
    "    if len(parts) >= 3:\n",
    "        day, month_dutch, year = parts[:3]\n",
    "        month_english = dutch_months.get(month_dutch.lower(), month_dutch)\n",
    "        date_str_english = f\"{day} {month_english} {year}\"\n",
    "        try:\n",
    "            # Convert the English date string to a datetime object\n",
    "            date_obj = datetime.datetime.strptime(date_str_english, \"%d %B %Y\")\n",
    "            # Convert datetime object to the desired string format\n",
    "            return date_obj.strftime(\"%d-%m-%Y\")\n",
    "        except ValueError:\n",
    "            return date_str  # Return the original on failure\n",
    "    return date_str  # Return the original if not enough parts\n",
    "\n",
    "# Apply the translation and conversion function to the 'Publication Date' column\n",
    "modified_data['Publication Date'] = modified_data['Publication Date'].apply(translate_date)\n",
    "\n",
    "# Save the modified data back to Excel if needed\n",
    "modified_data.to_excel(\"/Users/helgegeurtjacobusmoes/Desktop/thesis data/Updated_Randomized_Sampled_Articles.xlsx\", index=False)\n",
    "\n",
    "# Display the corrected data with the new date format\n",
    "modified_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
